{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from cleaner import clean_years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the following lines to extract the texts from the XML files and apply some basic preprocessing steps to the raw texts.\n",
    "The preprocessing of the articles can take a long time, we advise to run these lines on small intervalls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the NDA, we can not post the data on Github, so you will have to get the data from the cluster and specify the path below. We assume that the texts are in xml files separated by month such as 01.xml, 02.xml, ... and classified into folders by year exactly as the data on the iccluster. For this example, we decided to retrieve the data from the \"Gazette de Lausanne\" between 1805 and 1825."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_DIR = 'data'\n",
    "DIR_XML_DATA = os.path.join(DATA_DIR, 'GDL')\n",
    "DIR_OUTPUT_PKL_FILES = os.path.join(DATA_DIR, 'GDL_pkl')\n",
    "year_start = 1805\n",
    "year_end = 1825\n",
    "clean_years(DIR_XML_DATA, DIR_OUTPUT_PKL_FILES, year_start, year_end, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionaries creations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sylb/anaconda3/lib/python3.5/site-packages/gensim/utils.py:1015: UserWarning: Pattern library is not installed, lemmatization won't be available.\n",
      "  warnings.warn(\"Pattern library is not installed, lemmatization won't be available.\")\n"
     ]
    }
   ],
   "source": [
    "from dictFunctions import create_dictionary, load_dictionary, load_dictionaries\n",
    "from dictFunctions import clean_dict_by_occ, merge_dictionaries\n",
    "from correctText import clean_dictionary, cleanAndSaveArticles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ranges = [(range(year,year+1)) for year in range(year_start,year_end+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DIR_OUTPUT_DICTIONARIES = os.path.join(DATA_DIR, 'GDL_dict')\n",
    "for range_values in ranges:\n",
    "    create_dictionary(range_values, DIR_OUTPUT_PKL_FILES, DIR_OUTPUT_DICTIONARIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "interval = 10\n",
    "years = range(year_start, year_end, interval)\n",
    "occs_clean = [2,3,3,3,5,5,5,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1805-1815 done\n",
      "1815-1825 done\n"
     ]
    }
   ],
   "source": [
    "for year in years:\n",
    "    dict_10years = load_dictionaries(DIR_OUTPUT_DICTIONARIES, year, year + interval)\n",
    "    dict_10years_cleaned = [clean_dict_by_occ(dictio, occs_clean) for dictio in dict_10years]\n",
    "    fileName = os.path.join(DIR_OUTPUT_DICTIONARIES, str(year) + '-' + str(year + interval) + '.pkl')\n",
    "    merge_dictionaries(dict_10years_cleaned, fileName)\n",
    "    print(str(year) + '-' + str(year + interval) + ' done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictPath = os.path.join(DIR_OUTPUT_DICTIONARIES, str(year_start) + '-' + str(year_start + interval) + '.pkl')\n",
    "dictionnaries = clean_dictionary(dictPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the following function, you can clean and correct part of the articles. Then the produced articles can be used in the other notebooks. This operation can take a very long time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 articles cleaned, 2137 remaining\n",
      "100 articles cleaned, 2037 remaining\n",
      "200 articles cleaned, 1937 remaining\n",
      "300 articles cleaned, 1837 remaining\n",
      "400 articles cleaned, 1737 remaining\n",
      "500 articles cleaned, 1637 remaining\n",
      "600 articles cleaned, 1537 remaining\n",
      "700 articles cleaned, 1437 remaining\n",
      "800 articles cleaned, 1337 remaining\n",
      "900 articles cleaned, 1237 remaining\n",
      "1000 articles cleaned, 1137 remaining\n",
      "1100 articles cleaned, 1037 remaining\n",
      "1200 articles cleaned, 937 remaining\n",
      "1300 articles cleaned, 837 remaining\n",
      "1400 articles cleaned, 737 remaining\n",
      "1500 articles cleaned, 637 remaining\n",
      "1600 articles cleaned, 537 remaining\n",
      "1700 articles cleaned, 437 remaining\n",
      "1800 articles cleaned, 337 remaining\n",
      "1900 articles cleaned, 237 remaining\n",
      "2000 articles cleaned, 137 remaining\n",
      "2100 articles cleaned, 37 remaining\n",
      "1805\n"
     ]
    }
   ],
   "source": [
    "DIR_OUTPUT_PKL_FILES_CLEANED = os.path.join(DATA_DIR, 'GDL_cleaned')\n",
    "cleanAndSaveArticles(DIR_OUTPUT_PKL_FILES, DIR_OUTPUT_PKL_FILES_CLEANED, year_start, year_start+1, dictionnaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
