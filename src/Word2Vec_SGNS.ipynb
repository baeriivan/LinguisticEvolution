{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGNS using Word2Vec as embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disclaimer: This script doesn't contain the cleaning of the data. \n",
    "\n",
    "It uses the cleaned data and train a model by applying Skip Gram with Negative Sample (SGNS). The paper that is used for reference for most of our implementation is here (https://arxiv.org/pdf/1605.09096.pdf). It also discuss on why using SGNS is pretty viable compared to SVD on large datasets.\n",
    "\n",
    "These two articles given a good insight on SGNS and why the negative sampling is a good idea on big data sets:\n",
    "- http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/\n",
    "- http://mccormickml.com/2017/01/11/word2vec-tutorial-part-2-negative-sampling/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case, we want to create models using deep learning for different periods of time, and compare the evolution of the vectors (for words) over time.\n",
    "\n",
    "As the creation of each model created different \"axes\" for words, we had to come up with a method to \"align\" those axes: The orthogonal Procrustes method was chosen and implemented (It should be mentionned that for computing convenience, only the words in both dictionnaries (of each period) were kept. An explanatory paper on Procrustes is available here (http://winvector.github.io/xDrift/orthApprox.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The representation of our word vectors of 300 dimensions into something more visual, such as a 2 dimentional space is performed using t-Distributed Stochastic Neighbor Embedding (t-SNE) by reducing dimentionality. The paper and code is available here :\n",
    "\n",
    "https://lvdmaaten.github.io/tsne/ \n",
    "\n",
    "Here is also an interesting site to grasp how t-SNE work and how it can go wrong: \n",
    "\n",
    "http://distill.pub/2016/misread-tsne/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some code for using the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bbaga/src/anaconda2/envs/py34/lib/python3.4/site-packages/gensim/utils.py:1015: UserWarning: Pattern library is not installed, lemmatization won't be available.\n",
      "  warnings.warn(\"Pattern library is not installed, lemmatization won't be available.\")\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from collections import Counter\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# import our own made functions\n",
    "from load import *\n",
    "from output import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create two model from two different periods by loading the pickle files \n",
    "# that were created after cleaning the data.\n",
    "\n",
    "# note that there are much more articles in recent years so the periods\n",
    "# must not necessarily be of the same length.\n",
    "data_old = loadYears(\"../data/Cleaned/GDL\", range(1798,1860))\n",
    "data_new = loadYears(\"../data/Cleaned/GDL\", range(1950,1960))\n",
    "\n",
    "model_old = createModel(data_old)\n",
    "model_new = createModel(data_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now, we create the transformation matrix using Procrustes, and apply it\n",
    "# to the earlier period. We then return the modified first model (with the\n",
    "# transformation applied) and the new model.\n",
    "\n",
    "modZ, modB = createTransformationMatrix(model_old,model_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we can call this function to compare the shift of a selected word, with a\n",
    "# certain number of neighbour for each period to get an idea of the related\n",
    "# words and context\n",
    "# t-SNE is used to show the multidimentional vectors of 300 features\n",
    "# into a 2 dimentional space.\n",
    "\n",
    "# the red dots are from the earlier datasets and the blue dots from the \n",
    "# most recent one. The arrow shows the shift estimated using t-SNE.\n",
    "\n",
    "# Note: t-SNE is stochastic, and thus it might give a different result at\n",
    "#   each trial. Just run it again if the result is not satisfactory.\n",
    "\n",
    "visualizeWord(modZ, modB, 'bâtiment', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: here insert just a couple of interesting words\n",
    "#    some ideas: armée, transport, ...\n",
    "visualizeWord(modZ, modB, 'vapeur', 4) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tools for quantifying semantic evolution is evolving quite rapidly and many solutions exist. Only a part of those solutions could be tried during that project. With a relatively short period of time we could obtain some interesting results and more results could emerge with some deeper pre-processing of that data, tuning of parameters, and so on... [TODO: insert the facebook stuff que t'as vu Sylvain ;)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
